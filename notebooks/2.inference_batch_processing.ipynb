{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "current_working_dir = os.getcwd()\n",
    "# get the path to directory \"pe_granular_analysis\"\n",
    "_path = current_working_dir[:current_working_dir.find(\"pe_granular_analysis\")+len(\"pe_granular_analysis\")]\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "\n",
    "from preprocessing.nifti_conversion import batch_convert_dicom_to_volume\n",
    "from preprocessing.dataframe_formatter import dataframe_norm\n",
    "from preprocessing.segmentation import segmentator_process, CustomSegmentator\n",
    "from preprocessing.segmentation import segmentation2bbox_batch_process\n",
    "from preprocessing.dataframe_formatter import add_path2df\n",
    "\n",
    "from configs.pe.pe_final import PELabelMask\n",
    "\n",
    "from explainer.utils.visualize_cam import overlap_cam_on_voxel\n",
    "from utils.data_visualizer import ColorImageSliceViewer3D\n",
    "from utils.base import format_input_path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build/load your dataframe here\n",
    "example_data_dir = os.path.join(_path, \"data\")\n",
    "example_output_dir = os.path.join(_path, \"temp\")\n",
    "\n",
    "example_pid = None\n",
    "example_study_uid_1 = \"7f6fb39566ed\"\n",
    "example_series_uid_1 = \"b34edb1a4de7\"\n",
    "\n",
    "example_study_uid_2 = \"00268ff88746\"\n",
    "example_series_uid_2 = \"75d23269adbd\"\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"PatientID\": None,\n",
    "        \"StudyInstanceUID\": example_study_uid_1,\n",
    "        \"SeriesInstanceUID\": example_series_uid_1,\n",
    "    },\n",
    "    {\n",
    "        \"PatientID\": None,\n",
    "        \"StudyInstanceUID\": example_study_uid_2,\n",
    "        \"SeriesInstanceUID\": example_series_uid_2,\n",
    "    },\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e77396",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_suids = batch_convert_dicom_to_volume(\n",
    "    df=df,\n",
    "    source_folder=example_data_dir,\n",
    "    output_folder=example_output_dir,\n",
    ")\n",
    "if len(err_suids) > 0:\n",
    "    print(\"Errors occurred during DICOM to volume conversion:\")\n",
    "    for error in err_suids:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"DICOM to volume conversion completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CustomSegmentator(task=\"lung\", device=\"cuda\")\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    _pid = row[\"PatientID\"] if \"PatientID\" in row else None\n",
    "    _study_uid = row[\"StudyInstanceUID\"] if \"StudyInstanceUID\" in row else None\n",
    "    _series_uid = row[\"SeriesInstanceUID\"] if \"SeriesInstanceUID\" in row else None\n",
    "    error = segmentator_process(\n",
    "        segmentator_instance=cs,\n",
    "        input_folder=example_output_dir,\n",
    "        pid=_pid,\n",
    "        study_uid=_study_uid,\n",
    "        series_uid=_series_uid,\n",
    "    )\n",
    "    if error is not None:\n",
    "        print(f\"Error occurred during segmentation for SeriesInstanceUID: {_series_uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = segmentation2bbox_batch_process(df, task=\"lung\", input_folder=example_output_dir, save_path=example_output_dir)\n",
    "df = add_path2df(df, path=example_output_dir)\n",
    "df.to_csv(os.path.join(example_output_dir, \"lung_labels_bbox_with_path.csv\"), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cff829",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PELabelMask()\n",
    "cfg.ddp = False\n",
    "cfg.img_size = 256 # 256 used in training; 384 vs 256 depends on your GPU memory\n",
    "cfg.working_dir = example_output_dir\n",
    "cfg.test_result_dir = example_output_dir\n",
    "cfg.on_deploy = True\n",
    "cfg.on_grad_cam = False\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_instance = cfg.dataset_class(dataframe=df, usage=\"inference\", config=cfg)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_instance,\n",
    "    batch_size=1, # or more if memory allows\n",
    "    shuffle=False,\n",
    "    num_workers=0, # set to 0 for debugging, increase for speed if needed\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44fc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = cfg.get_model_setups()\n",
    "\n",
    "weight_paths = [os.path.join(\n",
    "    _path,\n",
    "   \"models/weights/example_weight.pth\"\n",
    ")]\n",
    "# define your weight paths here if you have multiple checkpoints\n",
    "# e.g., weight_paths = [path1, path2, path3]\n",
    "# weight_paths = []\n",
    "# for fold in range(5):\n",
    "#     weight_paths.append(os.path.join(\n",
    "#         _path,\n",
    "#        f\"models/weights/pe_coatnet_224_fold{fold}.pth\"\n",
    "#     ))\n",
    "\n",
    "models = []\n",
    "for weights_path in weight_paths:\n",
    "    model = cfg.model_class(**model_settings)\n",
    "    model.custom_load_from_checkpoint(weights_path)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_images = batch[\"images\"].cuda()\n",
    "        # if multiple models, average their outputs\n",
    "        for i, model in enumerate(models):\n",
    "            outputs = model(input_images)\n",
    "            if i == 0:\n",
    "                prediction = torch.sigmoid(outputs).cpu().numpy()\n",
    "            else:\n",
    "                prediction += torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction /= len(models)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "# flatten the list of predictions\n",
    "predictions = np.vstack(predictions).reshape(-1)\n",
    "# attach predictions to the dataframe\n",
    "df['pe_present_in_exam_pred'] = predictions\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to visualize some CAMs, you can use the following code\n",
    "\n",
    "# from explainer.explain_pipeline import explain\n",
    "# from explainer.configs.explainer_cfg import ExplainerConfig\n",
    "\n",
    "# explain_cfg = ExplainerConfig(dev_cfg=cfg)\n",
    "\n",
    "# model_weight_paths = os.path.join(\n",
    "#     _path,\n",
    "#    \"models/weights/ultimate.pe.aug.pth\"\n",
    "# )\n",
    "# cases_to_explain = df\n",
    "# test_name = \"cam_test\"\n",
    "\n",
    "# explain(cfg=explain_cfg, model_weight_paths=model_weight_paths, cases_to_explain=cases_to_explain, test_name=test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3eb644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
